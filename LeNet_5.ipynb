{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_6ZK9Etu3me2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,AveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.datasets import mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train) , (x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "4HUW-20OF34f"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train contains integer labels, convert them to one-hot encoding\n",
        "num_classes = 10  # Replace with the actual number of classes in your dataset\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "AhvoMRR1SFu-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "QgpXPj5JQR1x",
        "outputId": "ae0e2644-89e8-4f7a-ede2-b6c8287b2dd7"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d0b4439f970>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb/0lEQVR4nO3df3DU9b3v8dcGyAKaLIaYXxJoQAErkN4ipDkoxZJDSOdSEM4ZQP8AhwMXGjyF1OqkV0FbZ9LiqbU6EXrmtqTeEbDMEbhyzqEDwYSxTXBAuQxTm0MyUeCSBOVOsiFICMnn/sF1PSsB+l12886G52PmO0N2v+98P3y79cmX3XzxOeecAADoYwnWCwAA3J4IEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHYegFf1dPTo7NnzyopKUk+n896OQAAj5xzam9vV1ZWlhISrn+d0+8CdPbsWWVnZ1svAwBwi06fPq1Ro0Zd9/l+F6CkpCRJ0kP6rgZriPFqAABeXVGX3tO/hf57fj0xC1B5ebleeuklNTc3Kzc3V6+99pqmT59+07kv/tptsIZosI8AAUDc+f93GL3Z2ygx+RDCW2+9pZKSEm3cuFEffPCBcnNzVVhYqHPnzsXicACAOBSTAL388stauXKlnnjiCX3961/Xli1bNHz4cP32t7+NxeEAAHEo6gG6fPmyjh49qoKCgi8PkpCggoIC1dTUXLN/Z2engsFg2AYAGPiiHqDPPvtM3d3dSk9PD3s8PT1dzc3N1+xfVlamQCAQ2vgEHADcHsx/ELW0tFRtbW2h7fTp09ZLAgD0gah/Ci41NVWDBg1SS0tL2OMtLS3KyMi4Zn+/3y+/3x/tZQAA+rmoXwElJiZq6tSpqqysDD3W09OjyspK5efnR/twAIA4FZOfAyopKdGyZcv04IMPavr06XrllVfU0dGhJ554IhaHAwDEoZgEaPHixfr000+1YcMGNTc36xvf+Ib27dt3zQcTAAC3L59zzlkv4j8LBoMKBAKapfncCQEA4tAV16Uq7VFbW5uSk5Ovu5/5p+AAALcnAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgIuoBev755+Xz+cK2iRMnRvswAIA4NzgW3/SBBx7QgQMHvjzI4JgcBgAQx2JShsGDBysjIyMW3xoAMEDE5D2gkydPKisrS2PHjtXjjz+uU6dOXXffzs5OBYPBsA0AMPBFPUB5eXmqqKjQvn37tHnzZjU2Nurhhx9We3t7r/uXlZUpEAiEtuzs7GgvCQDQD/mccy6WB2htbdWYMWP08ssva8WKFdc839nZqc7OztDXwWBQ2dnZmqX5GuwbEsulAQBi4IrrUpX2qK2tTcnJydfdL+afDhgxYoTGjx+v+vr6Xp/3+/3y+/2xXgYAoJ+J+c8BXbhwQQ0NDcrMzIz1oQAAcSTqAXrqqadUXV2tjz/+WH/605/06KOPatCgQVq6dGm0DwUAiGNR/yu4M2fOaOnSpTp//rzuvvtuPfTQQ6qtrdXdd98d7UMBAOJY1AO0Y8eOaH9LAMAAxL3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATMf8H6YB4crnwQc8znzze43lmzTerPc+su+s/PM9EavL/eNLzzPAm7/+4cuvfdN58p68Y86b3Pzcn/uGI5xnEHldAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHdsDEgfbo6P6K5154u9zzzoL/b80xCBH/2W/ZxgeeZ/xI45XlGkv73P/wqojmvIjkPf5Oy1PNMyh88j6APcAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqToU74hiZ5nLhXkep75l9KXPM9IUtZgv+eZFZ/8reeZT/5pgueZO/71mOeZd4eP9jwjSdW7xnue+Zf7/ldEx/IqeGyk55mUGKwDt44rIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjRZ9qWvug55n3n/pVBEfyflNRSfr7+nmeZ64s6vI8M/yzw55nnOcJ6eyqqRFMSYfvi+Sce/fvF5M8z9z769OeZ654nkBf4AoIAGCCAAEATHgO0KFDhzRv3jxlZWXJ5/Np9+7dYc8757RhwwZlZmZq2LBhKigo0MmTJ6O1XgDAAOE5QB0dHcrNzVV5eXmvz2/atEmvvvqqtmzZosOHD+uOO+5QYWGhLl26dMuLBQAMHJ4/hFBUVKSioqJen3PO6ZVXXtGzzz6r+fPnS5LeeOMNpaena/fu3VqyZMmtrRYAMGBE9T2gxsZGNTc3q6CgIPRYIBBQXl6eampqep3p7OxUMBgM2wAAA19UA9Tc3CxJSk9PD3s8PT099NxXlZWVKRAIhLbs7OxoLgkA0E+ZfwqutLRUbW1toe30ae+f8QcAxJ+oBigjI0OS1NLSEvZ4S0tL6Lmv8vv9Sk5ODtsAAANfVAOUk5OjjIwMVVZWhh4LBoM6fPiw8vPzo3koAECc8/wpuAsXLqi+vj70dWNjo44dO6aUlBSNHj1a69at04svvqj77rtPOTk5eu6555SVlaUFCxZEc90AgDjnOUBHjhzRI488Evq6pKREkrRs2TJVVFTo6aefVkdHh1atWqXW1lY99NBD2rdvn4YOHRq9VQMA4p7PORfJPQ5jJhgMKhAIaJbma7BviPVycAMnX8vzPFO38HXPMz3q8Txz//7VnmckaeJTH3ue6f7sfETH6guP/vnTiOaeCHwc3YVcx8P//R89z9xV0fuPdKD/uOK6VKU9amtru+H7+uafggMA3J4IEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwvM/x4CBp+EX34porm5hueeZtp5Lnmf+/i+PeZ6Z8OR/eJ6RpO729ojmvEq44w7PM+f/bornmfl3vuR5RpISNMzzzMSdxZ5n7uXO1rc1roAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjHSAGZSe5nnmd4++HtGxetTjeSaSG4sm/u0nnme8ryxyCd/4uueZSb/9yPPMi+mvep6R/BHMSDOOLfE8M+F577+nbs8TGEi4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAz0gHGN9T7zScf9PfdLSGH/WOi5xnfmGzPMydXj/I8I0lzCj7wPLM+7Z89z4wePMzzTCQ3WO12LoIpyfdWqvdjtZ6M6Fi4fXEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakA4y71Ol55nDnkIiOlefv8jyz58AOzzM9Ed2Gs+8c+Nz7jTtPdnm/Segjwy54njly2fvNXyVpxBs1Ec0BXnAFBAAwQYAAACY8B+jQoUOaN2+esrKy5PP5tHv37rDnly9fLp/PF7bNnTs3WusFAAwQngPU0dGh3NxclZeXX3efuXPnqqmpKbRt3779lhYJABh4PH8IoaioSEVFRTfcx+/3KyMjI+JFAQAGvpi8B1RVVaW0tDRNmDBBa9as0fnz56+7b2dnp4LBYNgGABj4oh6guXPn6o033lBlZaV+/vOfq7q6WkVFReru7u51/7KyMgUCgdCWnZ0d7SUBAPqhqP8c0JIlS0K/njx5sqZMmaJx48apqqpKs2fPvmb/0tJSlZSUhL4OBoNECABuAzH/GPbYsWOVmpqq+vr6Xp/3+/1KTk4O2wAAA1/MA3TmzBmdP39emZmZsT4UACCOeP4ruAsXLoRdzTQ2NurYsWNKSUlRSkqKXnjhBS1atEgZGRlqaGjQ008/rXvvvVeFhYVRXTgAIL55DtCRI0f0yCOPhL7+4v2bZcuWafPmzTp+/Lh+97vfqbW1VVlZWZozZ45++tOfyu/3R2/VAIC453POeb8rYgwFg0EFAgHN0nwN9kV2k0x4c7nwwYjm/mnL655npiQO8jzzRvAezzMvVn/P84wkja+45HlmcEub55m07f/X88yW7IOeZybuW+N5RpLGrzgS0RwgSVdcl6q0R21tbTd8X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE1P9JbsSfxD9EdufjH+dMj/JKome83u+zY7XP934e/nX0Hs8zXc77nxeHfZzoeQboK1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpcIuuDPP+57gu1+15pkc9nmdyKk55npGkKxFNAd5wBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpMAtStpR633oF9FfBxBvuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1LgFrUv+VYEU0ejvg4g3nAFBAAwQYAAACY8BaisrEzTpk1TUlKS0tLStGDBAtXV1YXtc+nSJRUXF2vkyJG68847tWjRIrW0tER10QCA+OcpQNXV1SouLlZtba3279+vrq4uzZkzRx0dHaF91q9fr3feeUc7d+5UdXW1zp49q4ULF0Z94QCA+ObpQwj79u0L+7qiokJpaWk6evSoZs6cqba2Nv3mN7/Rtm3b9J3vfEeStHXrVt1///2qra3Vt74VyZu1AICB6JbeA2pra5MkpaSkSJKOHj2qrq4uFRQUhPaZOHGiRo8erZqaml6/R2dnp4LBYNgGABj4Ig5QT0+P1q1bpxkzZmjSpEmSpObmZiUmJmrEiBFh+6anp6u5ubnX71NWVqZAIBDasrOzI10SACCORByg4uJinThxQjt27LilBZSWlqqtrS20nT59+pa+HwAgPkT0g6hr167V3r17dejQIY0aNSr0eEZGhi5fvqzW1tawq6CWlhZlZGT0+r38fr/8fn8kywAAxDFPV0DOOa1du1a7du3SwYMHlZOTE/b81KlTNWTIEFVWVoYeq6ur06lTp5Sfnx+dFQMABgRPV0DFxcXatm2b9uzZo6SkpND7OoFAQMOGDVMgENCKFStUUlKilJQUJScn68knn1R+fj6fgAMAhPEUoM2bN0uSZs2aFfb41q1btXz5cknSL3/5SyUkJGjRokXq7OxUYWGhXn/99agsFgAwcHgKkHPupvsMHTpU5eXlKi8vj3hRQDxpG8sdrYBI8P8cAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIjoX0QF8KV7qi96nhmydpDnma6b34weiCtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXCLfH885nmmIpjmeWZp0v/xPHPxgUzPM5KUePpMRHOAF1wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpYOCXv/47zzNLn/qV55nM5+o9z0jS+dYp3odqj0d0LNy+uAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1LAwD3/s87zzOIF/9XzzFv37vU8I0nf3rDU80zKYwHPM92tbZ5nMHBwBQQAMEGAAAAmPAWorKxM06ZNU1JSktLS0rRgwQLV1YX/VcKsWbPk8/nCttWrV0d10QCA+OcpQNXV1SouLlZtba3279+vrq4uzZkzRx0dHWH7rVy5Uk1NTaFt06ZNUV00ACD+efoQwr59+8K+rqioUFpamo4ePaqZM2eGHh8+fLgyMjKis0IAwIB0S+8BtbVd/QRLSkpK2ONvvvmmUlNTNWnSJJWWlurixYvX/R6dnZ0KBoNhGwBg4Iv4Y9g9PT1at26dZsyYoUmTJoUef+yxxzRmzBhlZWXp+PHjeuaZZ1RXV6e333671+9TVlamF154IdJlAADiVMQBKi4u1okTJ/Tee++FPb5q1arQrydPnqzMzEzNnj1bDQ0NGjdu3DXfp7S0VCUlJaGvg8GgsrOzI10WACBORBSgtWvXau/evTp06JBGjRp1w33z8vIkSfX19b0GyO/3y+/3R7IMAEAc8xQg55yefPJJ7dq1S1VVVcrJybnpzLFjxyRJmZmZES0QADAweQpQcXGxtm3bpj179igpKUnNzc2SpEAgoGHDhqmhoUHbtm3Td7/7XY0cOVLHjx/X+vXrNXPmTE2ZMiUmvwEAQHzyFKDNmzdLuvrDpv/Z1q1btXz5ciUmJurAgQN65ZVX1NHRoezsbC1atEjPPvts1BYMABgYPP8V3I1kZ2erurr6lhYEALg9cDdswED3Z+c9z1xeNNLzzP2/+G+eZyTpo4Jfe5753sQV3g9Ue9z7DAYMbkYKADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqRAnIjkBqb3LfM+I0nf07QIprixKLzhCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJfncvOOecJOmKuiRnvBgAgGdX1CXpy/+eX0+/C1B7e7sk6T39m/FKAAC3or29XYFA4LrP+9zNEtXHenp6dPbsWSUlJcnn84U9FwwGlZ2drdOnTys5OdlohfY4D1dxHq7iPFzFebiqP5wH55za29uVlZWlhITrv9PT766AEhISNGrUqBvuk5ycfFu/wL7AebiK83AV5+EqzsNV1ufhRlc+X+BDCAAAEwQIAGAirgLk9/u1ceNG+f1+66WY4jxcxXm4ivNwFefhqng6D/3uQwgAgNtDXF0BAQAGDgIEADBBgAAAJggQAMBE3ASovLxcX/va1zR06FDl5eXp/ffft15Sn3v++efl8/nCtokTJ1ovK+YOHTqkefPmKSsrSz6fT7t37w573jmnDRs2KDMzU8OGDVNBQYFOnjxps9gYutl5WL58+TWvj7lz59osNkbKyso0bdo0JSUlKS0tTQsWLFBdXV3YPpcuXVJxcbFGjhypO++8U4sWLVJLS4vRimPjrzkPs2bNuub1sHr1aqMV9y4uAvTWW2+ppKREGzdu1AcffKDc3FwVFhbq3Llz1kvrcw888ICamppC23vvvWe9pJjr6OhQbm6uysvLe31+06ZNevXVV7VlyxYdPnxYd9xxhwoLC3Xp0qU+Xmls3ew8SNLcuXPDXh/bt2/vwxXGXnV1tYqLi1VbW6v9+/erq6tLc+bMUUdHR2if9evX65133tHOnTtVXV2ts2fPauHChYarjr6/5jxI0sqVK8NeD5s2bTJa8XW4ODB9+nRXXFwc+rq7u9tlZWW5srIyw1X1vY0bN7rc3FzrZZiS5Hbt2hX6uqenx2VkZLiXXnop9Fhra6vz+/1u+/btBivsG189D845t2zZMjd//nyT9Vg5d+6ck+Sqq6udc1f/tx8yZIjbuXNnaJ+PPvrISXI1NTVWy4y5r54H55z79re/7X7wgx/YLeqv0O+vgC5fvqyjR4+qoKAg9FhCQoIKCgpUU1NjuDIbJ0+eVFZWlsaOHavHH39cp06dsl6SqcbGRjU3N4e9PgKBgPLy8m7L10dVVZXS0tI0YcIErVmzRufPn7deUky1tbVJklJSUiRJR48eVVdXV9jrYeLEiRo9evSAfj189Tx84c0331RqaqomTZqk0tJSXbx40WJ519Xvbkb6VZ999pm6u7uVnp4e9nh6err+8pe/GK3KRl5enioqKjRhwgQ1NTXphRde0MMPP6wTJ04oKSnJenkmmpubJanX18cXz90u5s6dq4ULFyonJ0cNDQ368Y9/rKKiItXU1GjQoEHWy4u6np4erVu3TjNmzNCkSZMkXX09JCYmasSIEWH7DuTXQ2/nQZIee+wxjRkzRllZWTp+/LieeeYZ1dXV6e233zZcbbh+HyB8qaioKPTrKVOmKC8vT2PGjNHvf/97rVixwnBl6A+WLFkS+vXkyZM1ZcoUjRs3TlVVVZo9e7bhymKjuLhYJ06cuC3eB72R652HVatWhX49efJkZWZmavbs2WpoaNC4ceP6epm96vd/BZeamqpBgwZd8ymWlpYWZWRkGK2qfxgxYoTGjx+v+vp666WY+eI1wOvjWmPHjlVqauqAfH2sXbtWe/fu1bvvvhv2z7dkZGTo8uXLam1tDdt/oL4ernceepOXlydJ/er10O8DlJiYqKlTp6qysjL0WE9PjyorK5Wfn2+4MnsXLlxQQ0ODMjMzrZdiJicnRxkZGWGvj2AwqMOHD9/2r48zZ87o/PnzA+r14ZzT2rVrtWvXLh08eFA5OTlhz0+dOlVDhgwJez3U1dXp1KlTA+r1cLPz0Jtjx45JUv96PVh/CuKvsWPHDuf3+11FRYX785//7FatWuVGjBjhmpubrZfWp374wx+6qqoq19jY6P74xz+6goICl5qa6s6dO2e9tJhqb293H374ofvwww+dJPfyyy+7Dz/80H3yySfOOed+9rOfuREjRrg9e/a448ePu/nz57ucnBz3+eefG688um50Htrb291TTz3lampqXGNjoztw4ID75je/6e677z536dIl66VHzZo1a1wgEHBVVVWuqakptF28eDG0z+rVq93o0aPdwYMH3ZEjR1x+fr7Lz883XHX03ew81NfXu5/85CfuyJEjrrGx0e3Zs8eNHTvWzZw503jl4eIiQM4599prr7nRo0e7xMREN336dFdbW2u9pD63ePFil5mZ6RITE90999zjFi9e7Orr662XFXPvvvuuk3TNtmzZMufc1Y9iP/fccy49Pd35/X43e/ZsV1dXZ7voGLjRebh48aKbM2eOu/vuu92QIUPcmDFj3MqVKwfcH9J6+/1Lclu3bg3t8/nnn7vvf//77q677nLDhw93jz76qGtqarJbdAzc7DycOnXKzZw506WkpDi/3+/uvfde96Mf/ci1tbXZLvwr+OcYAAAm+v17QACAgYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMPH/APxZpiXrsXFLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[4].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydl4UlsQmNJ",
        "outputId": "2e2b034f-9b20-4ddd-e0bf-be6b3e08d6e3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6,kernel_size = (5,5),padding = 'valid', activation = 'tanh', input_shape = (28,28,1)))\n",
        "model.add(AveragePooling2D(strides = 2,pool_size = (2,2),padding  = 'valid'))\n",
        "\n",
        "model.add(Conv2D(16, padding = 'valid', kernel_size = (5,5),activation = 'tanh'))\n",
        "model.add(AveragePooling2D(strides = 2, pool_size = (2,2), padding = 'valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120,activation = 'tanh'))\n",
        "model.add(Dense(84, activation = 'tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pegc9tMDG6L2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfTN-SKVLMHm",
        "outputId": "26db17b5-4586-4a04-fd6f-667a73b5787f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_17 (Aver  (None, 12, 12, 6)         0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_18 (Aver  (None, 4, 4, 16)          0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44426 (173.54 KB)\n",
            "Trainable params: 44426 (173.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "naq6BIuyNOje"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs = 10,validation_data=(x_test,y_test) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIKhJvixMfd4",
        "outputId": "2c2fcc75-9e64-4d07-840c-1d24c6b60546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 30s 15ms/step - loss: 0.1590 - accuracy: 0.9532 - val_loss: 0.0602 - val_accuracy: 0.9812\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.0535 - val_accuracy: 0.9842\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0414 - val_accuracy: 0.9871\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0398 - accuracy: 0.9876 - val_loss: 0.0555 - val_accuracy: 0.9820\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0391 - val_accuracy: 0.9876\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0404 - val_accuracy: 0.9886\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0433 - val_accuracy: 0.9881\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0375 - val_accuracy: 0.9893\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.0429 - val_accuracy: 0.9885\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0431 - val_accuracy: 0.9889\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0526 - val_accuracy: 0.9863\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0389 - val_accuracy: 0.9899\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0426 - val_accuracy: 0.9886\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0468 - val_accuracy: 0.9879\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0452 - val_accuracy: 0.9886\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.0466 - val_accuracy: 0.9873\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.0463 - val_accuracy: 0.9875\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0462 - val_accuracy: 0.9873\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0457 - val_accuracy: 0.9894\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0475 - val_accuracy: 0.9882\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0483 - val_accuracy: 0.9887\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0483 - val_accuracy: 0.9891\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0433 - val_accuracy: 0.9903\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0508 - val_accuracy: 0.9872\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0464 - val_accuracy: 0.9884\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0475 - val_accuracy: 0.9884\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0475 - val_accuracy: 0.9899\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0590 - val_accuracy: 0.9871\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0580 - val_accuracy: 0.9880\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0642 - val_accuracy: 0.9860\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0531 - val_accuracy: 0.9890\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0564 - val_accuracy: 0.9877\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0544 - val_accuracy: 0.9881\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0481 - val_accuracy: 0.9893\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0497 - val_accuracy: 0.9890\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0487 - val_accuracy: 0.9879\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0542 - val_accuracy: 0.9886\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0472 - val_accuracy: 0.9887\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0587 - val_accuracy: 0.9880\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0505 - val_accuracy: 0.9885\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0477 - val_accuracy: 0.9905\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0459 - val_accuracy: 0.9897\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0423 - val_accuracy: 0.9918\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0518 - val_accuracy: 0.9894\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0564 - val_accuracy: 0.9879\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0568 - val_accuracy: 0.9875\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0521 - val_accuracy: 0.9899\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0553 - val_accuracy: 0.9889\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0569 - val_accuracy: 0.9881\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0593 - val_accuracy: 0.9873\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0656 - val_accuracy: 0.9871\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0551 - val_accuracy: 0.9883\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9874\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0619 - val_accuracy: 0.9879\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.0591 - val_accuracy: 0.9875\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0592 - val_accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0562 - val_accuracy: 0.9884\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0611 - val_accuracy: 0.9870\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0616 - val_accuracy: 0.9867\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0612 - val_accuracy: 0.9876\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0538 - val_accuracy: 0.9883\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0728 - val_accuracy: 0.9845\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.0687 - val_accuracy: 0.9871\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0676 - val_accuracy: 0.9866\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0620 - val_accuracy: 0.9872\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0543 - val_accuracy: 0.9882\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0636 - val_accuracy: 0.9872\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0581 - val_accuracy: 0.9882\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0566 - val_accuracy: 0.9887\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0641 - val_accuracy: 0.9862\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0577 - val_accuracy: 0.9887\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0604 - val_accuracy: 0.9883\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0532 - val_accuracy: 0.9896\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0630 - val_accuracy: 0.9874\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0787 - val_accuracy: 0.9848\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0604 - val_accuracy: 0.9882\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0659 - val_accuracy: 0.9866\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0571 - val_accuracy: 0.9886\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0652 - val_accuracy: 0.9880\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0658 - val_accuracy: 0.9855\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0678 - val_accuracy: 0.9867\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0583 - val_accuracy: 0.9894\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0576 - val_accuracy: 0.9891\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0616 - val_accuracy: 0.9883\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0561 - val_accuracy: 0.9891\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0618 - val_accuracy: 0.9876\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0555 - val_accuracy: 0.9898\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0661 - val_accuracy: 0.9874\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0685 - val_accuracy: 0.9878\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0662 - val_accuracy: 0.9876\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0606 - val_accuracy: 0.9885\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0713 - val_accuracy: 0.9874\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0053 - accuracy: 0.9980 - val_loss: 0.0688 - val_accuracy: 0.9879\n",
            "Epoch 100/100\n",
            " 595/1875 [========>.....................] - ETA: 16s - loss: 0.0032 - accuracy: 0.9993"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQ299hs8OkrW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}